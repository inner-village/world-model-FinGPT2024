{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4d096e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.56.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/imac27/FinGPT_2024/finGPT_env/lib/python3.10/site-packages (from openai) (4.6.2.post1)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/imac27/FinGPT_2024/finGPT_env/lib/python3.10/site-packages (from openai) (0.28.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.10.2-py3-none-any.whl.metadata (170 kB)\n",
      "Requirement already satisfied: sniffio in /Users/imac27/FinGPT_2024/finGPT_env/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/imac27/FinGPT_2024/finGPT_env/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/imac27/FinGPT_2024/finGPT_env/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/imac27/FinGPT_2024/finGPT_env/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/imac27/FinGPT_2024/finGPT_env/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /Users/imac27/FinGPT_2024/finGPT_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/imac27/FinGPT_2024/finGPT_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/imac27/FinGPT_2024/finGPT_env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.27.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Downloading openai-1.56.0-py3-none-any.whl (389 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.8.0-cp310-cp310-macosx_11_0_arm64.whl (311 kB)\n",
      "Downloading pydantic-2.10.2-py3-none-any.whl (456 kB)\n",
      "Downloading pydantic_core-2.27.1-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: pydantic-core, jiter, distro, annotated-types, pydantic, openai\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.8.0 openai-1.56.0 pydantic-2.10.2 pydantic-core-2.27.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import finnhub\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace9fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = \"2022-12-31\"\n",
    "END_DATE = \"2023-05-31\"\n",
    "\n",
    "DATA_DIR = f\"./{START_DATE}_{END_DATE}\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "import os　#.envで設定済み\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")　\n",
    "\n",
    "import os　#.envで設定済み\n",
    "import finnhub\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "finnhub_client = finnhub.Client(api_key=os.getenv(\"FINNHUB_CLIENT_KEY\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce2503",
   "metadata": {},
   "source": [
    "# Raw Financial Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6564114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 98\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# 実行部分\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m DOW_30:\n\u001b[0;32m---> 98\u001b[0m     \u001b[43mprepare_data_for_company\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 86\u001b[0m, in \u001b[0;36mprepare_data_for_company\u001b[0;34m(symbol, with_basics)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data_for_company\u001b[39m(symbol, with_basics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 86\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mget_returns\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     data \u001b[38;5;241m=\u001b[39m get_news(symbol, data)\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m with_basics:\n",
      "Cell \u001b[0;32mIn[5], line 50\u001b[0m, in \u001b[0;36mget_returns\u001b[0;34m(stock_symbol)\u001b[0m\n\u001b[1;32m     47\u001b[0m returns \u001b[38;5;241m=\u001b[39m returns[:min_length]\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# データフレーム作成\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m weekly_data_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStart Date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_prices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStart Price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_prices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnd Date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_prices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnd Price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_prices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeekly Returns\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturns\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# ラベル付け\u001b[39;00m\n\u001b[1;32m     59\u001b[0m weekly_data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBin Label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m weekly_data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeekly Returns\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(bin_mapping)\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/core/internals/construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    662\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "def bin_mapping(ret):\n",
    "    \n",
    "    up_down = 'U' if ret >= 0 else 'D'\n",
    "    integer = math.ceil(abs(100 * ret))\n",
    "    \n",
    "    return up_down + (str(integer) if integer <= 5 else '5+')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# データ取得期間の設定\n",
    "START_DATE = '2023-01-01'\n",
    "END_DATE = '2023-12-31'\n",
    "DATA_DIR = './data'\n",
    "DOW_30 = [\n",
    "    \"AXP\", \"AMGN\", \"AAPL\", \"BA\", \"CAT\", \"CSCO\", \"CVX\", \"GS\", \"HD\", \"HON\",\n",
    "    \"IBM\", \"INTC\", \"JNJ\", \"KO\", \"JPM\", \"MCD\", \"MMM\", \"MRK\", \"MSFT\", \"NKE\",\n",
    "    \"PG\", \"TRV\", \"UNH\", \"CRM\", \"VZ\", \"V\", \"WBA\", \"WMT\", \"DIS\", \"DOW\"\n",
    "]\n",
    "\n",
    "def bin_mapping(ret):\n",
    "    up_down = 'U' if ret >= 0 else 'D'\n",
    "    integer = math.ceil(abs(100 * ret))\n",
    "    return up_down + (str(integer) if integer <= 5 else '5+')\n",
    "\n",
    "def get_returns(stock_symbol):\n",
    "    # 株価データを取得\n",
    "    stock_data = yf.download(stock_symbol, start=START_DATE, end=END_DATE)\n",
    "    weekly_data = stock_data['Adj Close'].resample('W').ffill()\n",
    "\n",
    "    # 始値・終値・リターンを計算\n",
    "    start_prices = weekly_data[:-1]\n",
    "    end_prices = weekly_data[1:]\n",
    "    returns = (end_prices.values - start_prices.values) / start_prices.values\n",
    "\n",
    "    # データ長の揃え\n",
    "    min_length = min(len(start_prices), len(end_prices))\n",
    "    start_prices = start_prices[:min_length]\n",
    "    end_prices = end_prices[:min_length]\n",
    "    returns = returns[:min_length]\n",
    "\n",
    "    # データフレーム作成\n",
    "    weekly_data_df = pd.DataFrame({\n",
    "        'Start Date': start_prices.index,\n",
    "        'Start Price': start_prices.values,\n",
    "        'End Date': end_prices.index,\n",
    "        'End Price': end_prices.values,\n",
    "        'Weekly Returns': returns\n",
    "    })\n",
    "\n",
    "    # ラベル付け\n",
    "    weekly_data_df['Bin Label'] = weekly_data_df['Weekly Returns'].map(bin_mapping)\n",
    "    return weekly_data_df\n",
    "\n",
    "def get_news(symbol, data):\n",
    "    # ニュース取得ロジック\n",
    "    news_list = []\n",
    "    for _, row in data.iterrows():\n",
    "        start_date = row['Start Date'].strftime('%Y-%m-%d')\n",
    "        end_date = row['End Date'].strftime('%Y-%m-%d')\n",
    "        print(symbol, ':', start_date, '-', end_date)\n",
    "        time.sleep(1)  # QPM制御\n",
    "        # ニュース取得処理（finnhubのAPIを呼び出し）\n",
    "        weekly_news = [\n",
    "            {\"date\": \"20230101\", \"headline\": \"Sample Headline\", \"summary\": \"Sample Summary\"}\n",
    "        ]  # ダミーデータ\n",
    "        news_list.append(json.dumps(weekly_news))\n",
    "    data['News'] = news_list\n",
    "    return data\n",
    "\n",
    "def get_basics(symbol, data, always=False):\n",
    "    # 基本財務情報取得（ダミー実装）\n",
    "    basic_financials = {'series': {'quarterly': {\"Revenue\": [{\"period\": \"2023-01-01\", \"v\": 100}]}}}\n",
    "    final_basics = [json.dumps(basic_financials)] * len(data)\n",
    "    data['Basics'] = final_basics\n",
    "    return data\n",
    "\n",
    "def prepare_data_for_company(symbol, with_basics=True):\n",
    "    data = get_returns(symbol)\n",
    "    data = get_news(symbol, data)\n",
    "    if with_basics:\n",
    "        data = get_basics(symbol, data)\n",
    "        data.to_csv(f\"{DATA_DIR}/{symbol}_{START_DATE}_{END_DATE}.csv\")\n",
    "    else:\n",
    "        data['Basics'] = [json.dumps({})] * len(data)\n",
    "        data.to_csv(f\"{DATA_DIR}/{symbol}_{START_DATE}_{END_DATE}_nobasics.csv\")\n",
    "    return data\n",
    "\n",
    "# 実行部分\n",
    "for symbol in DOW_30:\n",
    "    prepare_data_for_company(symbol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf02ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOW_30 = [\n",
    "    \"AXP\", \"AMGN\", \"AAPL\", \"BA\", \"CAT\", \"CSCO\", \"CVX\", \"GS\", \"HD\", \"HON\",\n",
    "    \"IBM\", \"INTC\", \"JNJ\", \"KO\", \"JPM\", \"MCD\", \"MMM\", \"MRK\", \"MSFT\", \"NKE\",\n",
    "    \"PG\", \"TRV\", \"UNH\", \"CRM\", \"VZ\", \"V\", \"WBA\", \"WMT\", \"DIS\", \"DOW\"\n",
    "]\n",
    "\n",
    "# prepare_data_for_company(\"DOW\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d65960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m DOW_30:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mprepare_data_for_company\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     prepare_data_for_company(symbol, False)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 115\u001b[0m, in \u001b[0;36mprepare_data_for_company\u001b[0;34m(symbol, with_basics)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data_for_company\u001b[39m(symbol, with_basics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 115\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mget_returns\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     data \u001b[38;5;241m=\u001b[39m get_news(symbol, data)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m with_basics:\n",
      "Cell \u001b[0;32mIn[1], line 31\u001b[0m, in \u001b[0;36mget_returns\u001b[0;34m(stock_symbol)\u001b[0m\n\u001b[1;32m     28\u001b[0m weekly_returns \u001b[38;5;241m=\u001b[39m weekly_data\u001b[38;5;241m.\u001b[39mpct_change()\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# データフレームを作成\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m weekly_data_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStart Date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweekly_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStart Price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweekly_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnd Date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweekly_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnd Price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweekly_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeekly Returns\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweekly_returns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# ラベル付け\u001b[39;00m\n\u001b[1;32m     40\u001b[0m weekly_data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBin Label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m weekly_data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeekly Returns\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(bin_mapping)\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/core/internals/construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    662\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "for symbol in DOW_30:\n",
    "    prepare_data_for_company(symbol)\n",
    "#     prepare_data_for_company(symbol, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af655d8b",
   "metadata": {},
   "source": [
    "# Generate Prompt from Financial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a53c0ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_company_prompt(symbol):\n",
    "    \n",
    "    profile = finnhub_client.company_profile2(symbol=symbol)\n",
    "\n",
    "    company_template = \"[Company Introduction]:\\n\\n{name} is a leading entity in the {finnhubIndustry} sector. Incorporated and publicly traded since {ipo}, the company has established its reputation as one of the key players in the market. As of today, {name} has a market capitalization of {marketCapitalization:.2f} in {currency}, with {shareOutstanding:.2f} shares outstanding.\" \\\n",
    "        \"\\n\\n{name} operates primarily in the {country}, trading under the ticker {ticker} on the {exchange}. As a dominant force in the {finnhubIndustry} space, the company continues to innovate and drive progress within the industry.\"\n",
    "\n",
    "    formatted_str = company_template.format(**profile)\n",
    "    \n",
    "    return formatted_str\n",
    "\n",
    "\n",
    "def get_prompt_by_row(symbol, row):\n",
    "\n",
    "    start_date = row['Start Date'] if isinstance(row['Start Date'], str) else row['Start Date'].strftime('%Y-%m-%d')\n",
    "    end_date = row['End Date'] if isinstance(row['End Date'], str) else row['End Date'].strftime('%Y-%m-%d')\n",
    "    term = 'increased' if row['End Price'] > row['Start Price'] else 'decreased'\n",
    "    head = \"From {} to {}, {}'s stock price {} from {:.2f} to {:.2f}. Company news during this period are listed below:\\n\\n\".format(\n",
    "        start_date, end_date, symbol, term, row['Start Price'], row['End Price'])\n",
    "    \n",
    "    news = json.loads(row[\"News\"])\n",
    "    news = [\"[Headline]: {}\\n[Summary]: {}\\n\".format(\n",
    "        n['headline'], n['summary']) for n in news if n['date'][:8] <= end_date.replace('-', '') and \\\n",
    "        not n['summary'].startswith(\"Looking for stock market analysis and research with proves results?\")]\n",
    "\n",
    "    basics = json.loads(row['Basics'])\n",
    "    if basics:\n",
    "        basics = \"Some recent basic financials of {}, reported at {}, are presented below:\\n\\n[Basic Financials]:\\n\\n\".format(\n",
    "            symbol, basics['period']) + \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n",
    "    else:\n",
    "        basics = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n",
    "    \n",
    "    return head, news, basics\n",
    "\n",
    "\n",
    "def sample_news(news, k=5):\n",
    "    \n",
    "    return [news[i] for i in sorted(random.sample(range(len(news)), k))]\n",
    "\n",
    "\n",
    "def map_bin_label(bin_lb):\n",
    "    \n",
    "    lb = bin_lb.replace('U', 'up by ')\n",
    "    lb = lb.replace('D', 'down by ')\n",
    "    lb = lb.replace('1', '0-1%')\n",
    "    lb = lb.replace('2', '1-2%')\n",
    "    lb = lb.replace('3', '2-3%')\n",
    "    lb = lb.replace('4', '3-4%')\n",
    "    if lb.endswith('+'):\n",
    "        lb = lb.replace('5+', 'more than 5%')\n",
    "#         lb = lb.replace('5+', '5+%')\n",
    "    else:\n",
    "        lb = lb.replace('5', '4-5%')\n",
    "    \n",
    "    return lb\n",
    "\n",
    "\n",
    "def get_all_prompts(symbol, min_past_weeks=1, max_past_weeks=3, with_basics=True):\n",
    "\n",
    "    \n",
    "    if with_basics:\n",
    "        df = pd.read_csv(f'{DATA_DIR}/{symbol}_{START_DATE}_{END_DATE}.csv')\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_DIR}/{symbol}_{START_DATE}_{END_DATE}_nobasics.csv')\n",
    "    \n",
    "    company_prompt = get_company_prompt(symbol)\n",
    "\n",
    "    prev_rows = []\n",
    "    all_prompts = []\n",
    "\n",
    "    for row_idx, row in df.iterrows():\n",
    "\n",
    "        prompt = \"\"\n",
    "        if len(prev_rows) >= min_past_weeks:\n",
    "            idx = min(random.choice(range(min_past_weeks, max_past_weeks+1)), len(prev_rows))\n",
    "            for i in range(-idx, 0):\n",
    "                # Add Price Movement (Head)\n",
    "                prompt += \"\\n\" + prev_rows[i][0]\n",
    "                # Add News of previous weeks\n",
    "                sampled_news = sample_news(\n",
    "                    prev_rows[i][1],\n",
    "                    min(5, len(prev_rows[i][1]))\n",
    "                )\n",
    "                if sampled_news:\n",
    "                    prompt += \"\\n\".join(sampled_news)\n",
    "                else:\n",
    "                    prompt += \"No relative news reported.\"\n",
    "\n",
    "        head, news, basics = get_prompt_by_row(symbol, row)\n",
    "\n",
    "        prev_rows.append((head, news, basics))\n",
    "        if len(prev_rows) > max_past_weeks:\n",
    "            prev_rows.pop(0)  \n",
    "\n",
    "        if not prompt:\n",
    "            continue\n",
    "\n",
    "        prediction = map_bin_label(row['Bin Label'])\n",
    "        \n",
    "        prompt = company_prompt + '\\n' + prompt + '\\n' + basics\n",
    "        prompt += f\"\\n\\nBased on all the information before {row['Start Date']}, let's first analyze the positive developments and potential concerns for {symbol}. Come up with 2-4 most important factors respectively and keep them concise. Most factors should be inferred from company related news. \" \\\n",
    "            f\"Then let's assume your prediction for next week ({row['Start Date']} to {row['End Date']}) is {prediction}. Provide a summary analysis to support your prediction. The prediction result need to be inferred from your analysis at the end, and thus not appearing as a foundational factor of your analysis.\"\n",
    "\n",
    "        all_prompts.append(prompt.strip())\n",
    "    \n",
    "    return all_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92208b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a seasoned stock market analyst. Your task is to list the positive developments and potential concerns for companies based on relevant news and basic financials from the past weeks, then provide an analysis and prediction for the companies' stock price movement for the upcoming week. Your answer format should be as follows:\n",
      "\n",
      "[Positive Developments]:\n",
      "1. ...\n",
      "\n",
      "[Potential Concerns]:\n",
      "1. ...\n",
      "\n",
      "[Prediction & Analysis]:\n",
      "...\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/TRV_2023-01-01_2023-12-31.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(SYSTEM_PROMPT)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# prompts = get_all_prompts(\"AAPL\", 1, 3)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# prompts = get_all_prompts(\"MSFT\", 1, 3, False)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m prompts \u001b[38;5;241m=\u001b[39m \u001b[43mget_all_prompts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTRV\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(prompts[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[6], line 62\u001b[0m, in \u001b[0;36mget_all_prompts\u001b[0;34m(symbol, min_past_weeks, max_past_weeks, with_basics)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_prompts\u001b[39m(symbol, min_past_weeks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, max_past_weeks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, with_basics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m with_basics:\n\u001b[0;32m---> 62\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATA_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msymbol\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mSTART_DATE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mEND_DATE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSTART_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEND_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_nobasics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/TRV_2023-01-01_2023-12-31.csv'"
     ]
    }
   ],
   "source": [
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a seasoned stock market analyst. Your task is to list the positive developments and potential concerns for companies based on relevant news and basic financials from the past weeks, then provide an analysis and prediction for the companies' stock price movement for the upcoming week. \" \\\n",
    "    \"Your answer format should be as follows:\\n\\n[Positive Developments]:\\n1. ...\\n\\n[Potential Concerns]:\\n1. ...\\n\\n[Prediction & Analysis]:\\n...\\n\"\n",
    "\n",
    "print(SYSTEM_PROMPT)\n",
    "\n",
    "# prompts = get_all_prompts(\"AAPL\", 1, 3)\n",
    "# prompts = get_all_prompts(\"MSFT\", 1, 3, False)\n",
    "prompts = get_all_prompts(\"TRV\", 1, 4)\n",
    "\n",
    "print(prompts[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b010a45",
   "metadata": {},
   "source": [
    "# Request to GPT-4 for Financial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e355117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_csv(filename, input_data, output_data):\n",
    "    \n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([input_data, output_data])\n",
    "\n",
    "        \n",
    "def initialize_csv(filename):\n",
    "    \n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"prompt\", \"answer\"])\n",
    "\n",
    "\n",
    "def query_gpt4(symbol_list, min_past_weeks=1, max_past_weeks=3, with_basics=True):\n",
    "\n",
    "    for symbol in symbol_list:\n",
    "        \n",
    "        csv_file = f'{DATA_DIR}/{symbol}_{START_DATE}_{END_DATE}_gpt-4.csv' if with_basics else \\\n",
    "                   f'{DATA_DIR}/{symbol}_{START_DATE}_{END_DATE}_nobasics_gpt-4.csv'\n",
    "        \n",
    "        if not os.path.exists(csv_file):\n",
    "            initialize_csv(csv_file)\n",
    "            pre_done = 0\n",
    "        else:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            pre_done = len(df)\n",
    "\n",
    "        prompts = get_all_prompts(symbol, min_past_weeks, max_past_weeks, with_basics)\n",
    "\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            \n",
    "            if i < pre_done:\n",
    "                continue\n",
    "\n",
    "            print(f\"{symbol} - {i}\")\n",
    "            \n",
    "            cnt = 0\n",
    "            while cnt < 5:\n",
    "                try:\n",
    "                    completion = client.chat.completions.create(\n",
    "                        model=\"gpt-4\",\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                            {\"role\": \"user\", \"content\": prompt}\n",
    "                          ]\n",
    "                    )\n",
    "                    break    \n",
    "                except Exception:\n",
    "                    cnt += 1\n",
    "                    print(f'retry cnt {cnt}')\n",
    "            \n",
    "            answer = completion.choices[0].message.content if cnt < 5 else \"\"\n",
    "            append_to_csv(csv_file, prompt, answer)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ff6ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# query_gpt4(DOW_30, 1, 3)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mquery_gpt4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDOW_30\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# query_gpt4(['WBA'], 1, 4)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m, in \u001b[0;36mquery_gpt4\u001b[0;34m(symbol_list, min_past_weeks, max_past_weeks, with_basics)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m symbol_list:\n\u001b[1;32m     19\u001b[0m     csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSTART_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEND_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_gpt-4.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m with_basics \u001b[38;5;28;01melse\u001b[39;00m \\\n\u001b[1;32m     20\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSTART_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEND_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_nobasics_gpt-4.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(csv_file):\n\u001b[1;32m     23\u001b[0m         initialize_csv(csv_file)\n\u001b[1;32m     24\u001b[0m         pre_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# query_gpt4(DOW_30, 1, 3)\n",
    "query_gpt4(DOW_30, 1, 4)\n",
    "# query_gpt4(['WBA'], 1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ba9f0",
   "metadata": {},
   "source": [
    "# Transform into Llama2 Training Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2627f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt4_to_llama(symbol, with_basics=True):\n",
    "    \n",
    "    csv_file = f'{DATA_DIR}/{symbol}_{START_DATE}_{END_DATE}_gpt-4.csv' if with_basics else \\\n",
    "                   f'{DATA_DIR}/{symbol}_{START_DATE}_{END_DATE}_nobasics_gpt-4.csv'\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    prompts, answers, periods, labels = [], [], [], []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        \n",
    "        prompt, answer = row['prompt'], row['answer']\n",
    "        \n",
    "        res = re.search(r\"Then let's assume your prediction for next week \\((.*)\\) is ((:?up|down) by .*%).\", prompt)\n",
    "        \n",
    "        period, label = res.group(1), res.group(2)\n",
    "#         label = label.replace('more than 5', '5+')\n",
    "        \n",
    "        prompt = re.sub(\n",
    "            r\"Then let's assume your prediction for next week \\((.*)\\) is (up|down) by ((:?.*)%). Provide a summary analysis to support your prediction. The prediction result need to be inferred from your analysis at the end, and thus not appearing as a foundational factor of your analysis.\", \n",
    "            f\"Then make your prediction of the {symbol} stock price movement for next week ({period}). Provide a summary analysis to support your prediction.\",\n",
    "            prompt\n",
    "        )\n",
    "        try:\n",
    "            answer = re.sub(\n",
    "                r\"\\[Prediction & Analysis\\]:\\s*\",\n",
    "                f\"[Prediction & Analysis]:\\nPrediction: {label.capitalize()}\\nAnalysis: \",\n",
    "                answer\n",
    "            )\n",
    "        except Exception:\n",
    "            print(symbol, i)\n",
    "            print(label)\n",
    "            print(answer)\n",
    "            continue\n",
    "            \n",
    "        new_system_prompt = SYSTEM_PROMPT.replace(':\\n...', '\\nPrediction: ...\\nAnalysis: ...')\n",
    "#         new_system_prompt = SYSTEM_PROMPT.replace(':\\n...', '\\nPrediction: {Up|Down} by {1-2|2-3|3-4|4-5|5+}%\\nAnalysis: ...')\n",
    "        \n",
    "        prompt = B_INST + B_SYS + new_system_prompt + E_SYS + prompt + E_INST\n",
    "        \n",
    "        prompts.append(prompt)\n",
    "        answers.append(answer)\n",
    "        periods.append(period)\n",
    "        labels.append(label)\n",
    "        \n",
    "    return {\n",
    "        \"prompt\": prompts,\n",
    "        \"answer\": answers,\n",
    "        \"period\": periods,\n",
    "        \"label\": labels,\n",
    "    }\n",
    "\n",
    "\n",
    "def create_dataset(symbol_list, train_ratio=0.8, with_basics=True):\n",
    "\n",
    "    train_dataset_list = []\n",
    "    test_dataset_list = []\n",
    "\n",
    "    for symbol in symbol_list:\n",
    "\n",
    "        data_dict = gpt4_to_llama(symbol, with_basics)\n",
    "#         print(data_dict['prompt'][-1])\n",
    "#         print(data_dict['answer'][-1])\n",
    "        symbols = [symbol] * len(data_dict['label'])\n",
    "        data_dict.update({\"symbol\": symbols})\n",
    "\n",
    "        dataset = Dataset.from_dict(data_dict)\n",
    "        train_size = round(train_ratio * len(dataset))\n",
    "\n",
    "        train_dataset_list.append(dataset.select(range(train_size)))\n",
    "        test_dataset_list.append(dataset.select(range(train_size, len(dataset))))\n",
    "\n",
    "    train_dataset = datasets.concatenate_datasets(train_dataset_list)\n",
    "    test_dataset = datasets.concatenate_datasets(test_dataset_list)\n",
    "\n",
    "    dataset = datasets.DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'test': test_dataset\n",
    "    })\n",
    "    \n",
    "    return dataset\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e089b1bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/AXP_2023-01-01_2023-12-31_gpt-4.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# v1\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# dow30_dataset = create_dataset(DOW30, True)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# v2\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# dow30_nobasic_dataset = create_dataset(DOW_30, 0.8, False)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# v3\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m dow30_v3_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDOW_30\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 61\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[0;34m(symbol_list, train_ratio, with_basics)\u001b[0m\n\u001b[1;32m     57\u001b[0m     test_dataset_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m symbol_list:\n\u001b[0;32m---> 61\u001b[0m         data_dict \u001b[38;5;241m=\u001b[39m \u001b[43mgpt4_to_llama\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_basics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#         print(data_dict['prompt'][-1])\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#         print(data_dict['answer'][-1])\u001b[39;00m\n\u001b[1;32m     64\u001b[0m         symbols \u001b[38;5;241m=\u001b[39m [symbol] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m, in \u001b[0;36mgpt4_to_llama\u001b[0;34m(symbol, with_basics)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgpt4_to_llama\u001b[39m(symbol, with_basics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m     csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSTART_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEND_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_gpt-4.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m with_basics \u001b[38;5;28;01melse\u001b[39;00m \\\n\u001b[1;32m      4\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSTART_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEND_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_nobasics_gpt-4.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     prompts, answers, periods, labels \u001b[38;5;241m=\u001b[39m [], [], [], []\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/AXP_2023-01-01_2023-12-31_gpt-4.csv'"
     ]
    }
   ],
   "source": [
    "# v1\n",
    "# dow30_dataset = create_dataset(DOW30, True)\n",
    "# v2\n",
    "# dow30_nobasic_dataset = create_dataset(DOW_30, 0.8, False)\n",
    "# v3\n",
    "dow30_v3_dataset = create_dataset(DOW_30, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "123f2db9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dow30_v3_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# dow30_dataset.save_to_disk('fingpt-forecaster-dow30-20230601-20230930-llama')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# dow30_nobasics_dataset.save_to_disk('fingpt-forecaster-dow30nobasics-20230601-20230930-llama')\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdow30_v3_dataset\u001b[49m\u001b[38;5;241m.\u001b[39msave_to_disk(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfingpt-forecaster-dow30v3-20221231-20230531-llama\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dow30_v3_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# dow30_dataset.save_to_disk('fingpt-forecaster-dow30-20230601-20230930-llama')\n",
    "# dow30_nobasics_dataset.save_to_disk('fingpt-forecaster-dow30nobasics-20230601-20230930-llama')\n",
    "dow30_v3_dataset.save_to_disk('fingpt-forecaster-dow30v3-20221231-20230531-llama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ed5cf5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dow30_v3_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdow30_v3_dataset\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dow30_v3_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dow30_v3_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62e711f",
   "metadata": {},
   "source": [
    "# Test-time Information Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "292268bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "\n",
    "def get_curday():\n",
    "    \n",
    "    return date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def n_weeks_before(date_string, n):\n",
    "    \n",
    "    date = datetime.strptime(date_string, \"%Y-%m-%d\") - timedelta(days=7*n)\n",
    "    \n",
    "    return date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def get_stock_data(stock_symbol, steps):\n",
    "\n",
    "    stock_data = yf.download(stock_symbol, steps[0], steps[-1])\n",
    "    \n",
    "#     print(stock_data)\n",
    "    \n",
    "    dates, prices = [], []\n",
    "    available_dates = stock_data.index.format()\n",
    "    \n",
    "    for date in steps[:-1]:\n",
    "        for i in range(len(stock_data)):\n",
    "            if available_dates[i] >= date:\n",
    "                prices.append(stock_data['Close'][i])\n",
    "                dates.append(datetime.strptime(available_dates[i], \"%Y-%m-%d\"))\n",
    "                break\n",
    "\n",
    "    dates.append(datetime.strptime(available_dates[-1], \"%Y-%m-%d\"))\n",
    "    prices.append(stock_data['Close'][-1])\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"Start Date\": dates[:-1], \"End Date\": dates[1:],\n",
    "        \"Start Price\": prices[:-1], \"End Price\": prices[1:]\n",
    "    })\n",
    "\n",
    "\n",
    "def get_current_basics(symbol, curday):\n",
    "\n",
    "    basic_financials = finnhub_client.company_basic_financials(symbol, 'all')\n",
    "    \n",
    "    final_basics, basic_list, basic_dict = [], [], defaultdict(dict)\n",
    "    \n",
    "    for metric, value_list in basic_financials['series']['quarterly'].items():\n",
    "        for value in value_list:\n",
    "            basic_dict[value['period']].update({metric: value['v']})\n",
    "\n",
    "    for k, v in basic_dict.items():\n",
    "        v.update({'period': k})\n",
    "        basic_list.append(v)\n",
    "        \n",
    "    basic_list.sort(key=lambda x: x['period'])\n",
    "    \n",
    "    for basic in basic_list[::-1]:\n",
    "        if basic['period'] <= curday:\n",
    "            break\n",
    "            \n",
    "    return basic\n",
    "    \n",
    "\n",
    "def get_all_prompts_online(symbol, data, curday, with_basics=True):\n",
    "\n",
    "    company_prompt = get_company_prompt(symbol)\n",
    "\n",
    "    prev_rows = []\n",
    "\n",
    "    for row_idx, row in data.iterrows():\n",
    "        head, news, _ = get_prompt_by_row(symbol, row)\n",
    "        prev_rows.append((head, news, None))\n",
    "        \n",
    "    prompt = \"\"\n",
    "    for i in range(-len(prev_rows), 0):\n",
    "        prompt += \"\\n\" + prev_rows[i][0]\n",
    "        sampled_news = sample_news(\n",
    "            prev_rows[i][1],\n",
    "            min(5, len(prev_rows[i][1]))\n",
    "        )\n",
    "        if sampled_news:\n",
    "            prompt += \"\\n\".join(sampled_news)\n",
    "        else:\n",
    "            prompt += \"No relative news reported.\"\n",
    "        \n",
    "    period = \"{} to {}\".format(curday, n_weeks_before(curday, -1))\n",
    "    \n",
    "    if with_basics:\n",
    "        basics = get_current_basics(symbol, curday)\n",
    "        basics = \"Some recent basic financials of {}, reported at {}, are presented below:\\n\\n[Basic Financials]:\\n\\n\".format(\n",
    "            symbol, basics['period']) + \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n",
    "    else:\n",
    "        basics = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n",
    "\n",
    "    info = company_prompt + '\\n' + prompt + '\\n' + basics\n",
    "    prompt = info + f\"\\n\\nBased on all the information before {curday}, let's first analyze the positive developments and potential concerns for {symbol}. Come up with 2-4 most important factors respectively and keep them concise. Most factors should be inferred from company related news. \" \\\n",
    "        f\"Then make your prediction of the {symbol} stock price movement for next week ({period}). Provide a summary analysis to support your prediction.\"\n",
    "        \n",
    "    return info, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f48aab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/fq/z8mcqs9106b5bkv0c5hlwyyw0000gw/T/ipykernel_12985/658630580.py:25: FutureWarning: DatetimeIndex.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
      "  available_dates = stock_data.index.format()\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m curday \u001b[38;5;241m=\u001b[39m get_curday()\n\u001b[1;32m      4\u001b[0m steps \u001b[38;5;241m=\u001b[39m [n_weeks_before(curday, n) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_weeks \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mget_stock_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m get_news(ticker, data)\n\u001b[1;32m     10\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBasics\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [json\u001b[38;5;241m.\u001b[39mdumps({})] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "Cell \u001b[0;32mIn[14], line 30\u001b[0m, in \u001b[0;36mget_stock_data\u001b[0;34m(stock_symbol, steps)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(stock_data)):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m available_dates[i] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m date:\n\u001b[0;32m---> 30\u001b[0m         prices\u001b[38;5;241m.\u001b[39mappend(\u001b[43mstock_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     31\u001b[0m         dates\u001b[38;5;241m.\u001b[39mappend(datetime\u001b[38;5;241m.\u001b[39mstrptime(available_dates[i], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/FinGPT_2024/finGPT_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "ticker = \"AAPL\"\n",
    "n_weeks = 2\n",
    "curday = get_curday()\n",
    "steps = [n_weeks_before(curday, n) for n in range(n_weeks + 1)][::-1]\n",
    "\n",
    "data = get_stock_data(ticker, steps)\n",
    "\n",
    "data = get_news(ticker, data)\n",
    "\n",
    "data['Basics'] = [json.dumps({})] * len(data)\n",
    "# data = get_basics(ticker, data, always=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "info, prompt = get_all_prompts_online(ticker, data, curday, False)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e9839-2df0-4e54-ab5b-f7562dde0734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c97742a-93af-46e3-b9d1-1bbb85896118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
